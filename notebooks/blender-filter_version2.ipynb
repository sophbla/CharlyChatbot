{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0b7b6a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0ddaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting better_profanity\n",
      "  Downloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: better_profanity\n",
      "Successfully installed better_profanity-0.7.0\n"
     ]
    }
   ],
   "source": [
    "! pip3 install better_profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f401b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vroni/.pyenv/versions/3.10.6/envs/MHConvoAI/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-10 20:59:44.122732: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# General \n",
    "\n",
    "# Blendebot\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "# Filter for bad words and trigger words\n",
    "from better_profanity import profanity \n",
    "\n",
    "# Detect neutral input, emotions and offensive language\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285b99b",
   "metadata": {},
   "source": [
    "# Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe16cb",
   "metadata": {},
   "source": [
    "## Trigger words and bad words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5465d52",
   "metadata": {},
   "source": [
    "**To do:**\n",
    "\n",
    "* Review lists of both, bad and trigger words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ed8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of bad words and trigger words from folder\n",
    "\n",
    "with open(\"../filter/trigger_words.txt\") as file:\n",
    "    trigger_words = [line.rstrip() for line in file]\n",
    "    \n",
    "with open(\"../filter/bad_words.txt\") as file:\n",
    "    bad_words = [line.rstrip() for line in file] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39bd7a61",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2g1c',\n",
       " '2 girls 1 cup',\n",
       " 'acrotomophilia',\n",
       " 'alabama hot pocket',\n",
       " 'alaskan pipeline',\n",
       " 'anal',\n",
       " 'anilingus',\n",
       " 'anus',\n",
       " 'apeshit',\n",
       " 'arsehole',\n",
       " 'ass',\n",
       " 'asshole',\n",
       " 'assmunch',\n",
       " 'auto erotic',\n",
       " 'autoerotic',\n",
       " 'babeland',\n",
       " 'baby batter',\n",
       " 'baby juice',\n",
       " 'ball gag',\n",
       " 'ball gravy',\n",
       " 'ball kicking',\n",
       " 'ball licking',\n",
       " 'ball sack',\n",
       " 'ball sucking',\n",
       " 'bangbros',\n",
       " 'bangbus',\n",
       " 'bareback',\n",
       " 'barely legal',\n",
       " 'barenaked',\n",
       " 'bastard',\n",
       " 'bastardo',\n",
       " 'bastinado',\n",
       " 'bbw',\n",
       " 'bdsm',\n",
       " 'beaner',\n",
       " 'beaners',\n",
       " 'beaver cleaver',\n",
       " 'beaver lips',\n",
       " 'beastiality',\n",
       " 'bestiality',\n",
       " 'big black',\n",
       " 'big breasts',\n",
       " 'big knockers',\n",
       " 'big tits',\n",
       " 'bimbos',\n",
       " 'birdlock',\n",
       " 'bitch',\n",
       " 'bitches',\n",
       " 'black cock',\n",
       " 'blonde action',\n",
       " 'blonde on blonde action',\n",
       " 'blowjob',\n",
       " 'blow job',\n",
       " 'blow your load',\n",
       " 'blue waffle',\n",
       " 'blumpkin',\n",
       " 'bollocks',\n",
       " 'bondage',\n",
       " 'boner',\n",
       " 'boob',\n",
       " 'boobs',\n",
       " 'booty call',\n",
       " 'brown showers',\n",
       " 'brunette action',\n",
       " 'bukkake',\n",
       " 'bulldyke',\n",
       " 'bullet vibe',\n",
       " 'bullshit',\n",
       " 'bung hole',\n",
       " 'bunghole',\n",
       " 'busty',\n",
       " 'butt',\n",
       " 'buttcheeks',\n",
       " 'butthole',\n",
       " 'camel toe',\n",
       " 'camgirl',\n",
       " 'camslut',\n",
       " 'camwhore',\n",
       " 'carpet muncher',\n",
       " 'carpetmuncher',\n",
       " 'chocolate rosebuds',\n",
       " 'cialis',\n",
       " 'circlejerk',\n",
       " 'cleveland steamer',\n",
       " 'clit',\n",
       " 'clitoris',\n",
       " 'clover clamps',\n",
       " 'clusterfuck',\n",
       " 'cock',\n",
       " 'cocks',\n",
       " 'coprolagnia',\n",
       " 'coprophilia',\n",
       " 'cornhole',\n",
       " 'coon',\n",
       " 'coons',\n",
       " 'creampie',\n",
       " 'cum',\n",
       " 'cumming',\n",
       " 'cumshot',\n",
       " 'cumshots',\n",
       " 'cunnilingus',\n",
       " 'cunt',\n",
       " 'darkie',\n",
       " 'date rape',\n",
       " 'daterape',\n",
       " 'deep throat',\n",
       " 'deepthroat',\n",
       " 'dendrophilia',\n",
       " 'dick',\n",
       " 'dildo',\n",
       " 'dingleberry',\n",
       " 'dingleberries',\n",
       " 'dirty pillows',\n",
       " 'dirty sanchez',\n",
       " 'doggie style',\n",
       " 'doggiestyle',\n",
       " 'doggy style',\n",
       " 'doggystyle',\n",
       " 'dog style',\n",
       " 'dolcett',\n",
       " 'domination',\n",
       " 'dominatrix',\n",
       " 'dommes',\n",
       " 'donkey punch',\n",
       " 'double dong',\n",
       " 'double penetration',\n",
       " 'dp action',\n",
       " 'dry hump',\n",
       " 'dvda',\n",
       " 'eat my ass',\n",
       " 'ecchi',\n",
       " 'ejaculation',\n",
       " 'erotic',\n",
       " 'erotism',\n",
       " 'escort',\n",
       " 'eunuch',\n",
       " 'fag',\n",
       " 'faggot',\n",
       " 'fecal',\n",
       " 'felch',\n",
       " 'fellatio',\n",
       " 'feltch',\n",
       " 'female squirting',\n",
       " 'femdom',\n",
       " 'figging',\n",
       " 'fingerbang',\n",
       " 'fingering',\n",
       " 'fisting',\n",
       " 'foot fetish',\n",
       " 'footjob',\n",
       " 'frotting',\n",
       " 'fuck',\n",
       " 'fuck buttons',\n",
       " 'fuckin',\n",
       " 'fucking',\n",
       " 'fucktards',\n",
       " 'fudge packer',\n",
       " 'fudgepacker',\n",
       " 'futanari',\n",
       " 'gangbang',\n",
       " 'gang bang',\n",
       " 'gay sex',\n",
       " 'genitals',\n",
       " 'giant cock',\n",
       " 'girl on',\n",
       " 'girl on top',\n",
       " 'girls gone wild',\n",
       " 'goatcx',\n",
       " 'goatse',\n",
       " 'god damn',\n",
       " 'gokkun',\n",
       " 'golden shower',\n",
       " 'goodpoop',\n",
       " 'goo girl',\n",
       " 'goregasm',\n",
       " 'grope',\n",
       " 'group sex',\n",
       " 'g-spot',\n",
       " 'guro',\n",
       " 'hand job',\n",
       " 'handjob',\n",
       " 'hard core',\n",
       " 'hardcore',\n",
       " 'hentai',\n",
       " 'homoerotic',\n",
       " 'honkey',\n",
       " 'hooker',\n",
       " 'horny',\n",
       " 'hot carl',\n",
       " 'hot chick',\n",
       " 'how to kill',\n",
       " 'how to murder',\n",
       " 'huge fat',\n",
       " 'humping',\n",
       " 'incest',\n",
       " 'intercourse',\n",
       " 'jack off',\n",
       " 'jail bait',\n",
       " 'jailbait',\n",
       " 'jelly donut',\n",
       " 'jerk off',\n",
       " 'jigaboo',\n",
       " 'jiggaboo',\n",
       " 'jiggerboo',\n",
       " 'jizz',\n",
       " 'juggs',\n",
       " 'kike',\n",
       " 'kinbaku',\n",
       " 'kinkster',\n",
       " 'kinky',\n",
       " 'knobbing',\n",
       " 'leather restraint',\n",
       " 'leather straight jacket',\n",
       " 'lemon party',\n",
       " 'livesex',\n",
       " 'lolita',\n",
       " 'lovemaking',\n",
       " 'make me come',\n",
       " 'male squirting',\n",
       " 'masturbate',\n",
       " 'masturbating',\n",
       " 'masturbation',\n",
       " 'menage a trois',\n",
       " 'milf',\n",
       " 'missionary position',\n",
       " 'mong',\n",
       " 'motherfucker',\n",
       " 'mound of venus',\n",
       " 'mr hands',\n",
       " 'muff diver',\n",
       " 'muffdiving',\n",
       " 'nambla',\n",
       " 'nawashi',\n",
       " 'negro',\n",
       " 'neonazi',\n",
       " 'nigga',\n",
       " 'nigger',\n",
       " 'nig nog',\n",
       " 'nimphomania',\n",
       " 'nipple',\n",
       " 'nipples',\n",
       " 'nsfw',\n",
       " 'nsfw images',\n",
       " 'nude',\n",
       " 'nudity',\n",
       " 'nutten',\n",
       " 'nympho',\n",
       " 'nymphomania',\n",
       " 'octopussy',\n",
       " 'omorashi',\n",
       " 'one cup two girls',\n",
       " 'one guy one jar',\n",
       " 'orgasm',\n",
       " 'orgy',\n",
       " 'paedophile',\n",
       " 'paki',\n",
       " 'panties',\n",
       " 'panty',\n",
       " 'pedobear',\n",
       " 'pedophile',\n",
       " 'pegging',\n",
       " 'penis',\n",
       " 'phone sex',\n",
       " 'piece of shit',\n",
       " 'pikey',\n",
       " 'pissing',\n",
       " 'piss pig',\n",
       " 'pisspig',\n",
       " 'playboy',\n",
       " 'pleasure chest',\n",
       " 'pole smoker',\n",
       " 'ponyplay',\n",
       " 'poof',\n",
       " 'poon',\n",
       " 'poontang',\n",
       " 'punany',\n",
       " 'poop chute',\n",
       " 'poopchute',\n",
       " 'porn',\n",
       " 'porno',\n",
       " 'pornography',\n",
       " 'prince albert piercing',\n",
       " 'pthc',\n",
       " 'pubes',\n",
       " 'pussy',\n",
       " 'queaf',\n",
       " 'queef',\n",
       " 'quim',\n",
       " 'raghead',\n",
       " 'raging boner',\n",
       " 'rape',\n",
       " 'raping',\n",
       " 'rapist',\n",
       " 'rectum',\n",
       " 'reverse cowgirl',\n",
       " 'rimjob',\n",
       " 'rimming',\n",
       " 'rosy palm',\n",
       " 'rosy palm and her 5 sisters',\n",
       " 'rusty trombone',\n",
       " 'sadism',\n",
       " 'santorum',\n",
       " 'scat',\n",
       " 'schlong',\n",
       " 'scissoring',\n",
       " 'semen',\n",
       " 'sex',\n",
       " 'sexcam',\n",
       " 'sexo',\n",
       " 'sexy',\n",
       " 'sexual',\n",
       " 'sexually',\n",
       " 'sexuality',\n",
       " 'shaved beaver',\n",
       " 'shaved pussy',\n",
       " 'shemale',\n",
       " 'shibari',\n",
       " 'shit',\n",
       " 'shitblimp',\n",
       " 'shitty',\n",
       " 'shota',\n",
       " 'shrimping',\n",
       " 'skeet',\n",
       " 'slanteye',\n",
       " 'slut',\n",
       " 's&m',\n",
       " 'smut',\n",
       " 'snatch',\n",
       " 'snowballing',\n",
       " 'sodomize',\n",
       " 'sodomy',\n",
       " 'spastic',\n",
       " 'spic',\n",
       " 'splooge',\n",
       " 'splooge moose',\n",
       " 'spooge',\n",
       " 'spread legs',\n",
       " 'spunk',\n",
       " 'strap on',\n",
       " 'strapon',\n",
       " 'strappado',\n",
       " 'strip club',\n",
       " 'style doggy',\n",
       " 'suck',\n",
       " 'sucks',\n",
       " 'suicide girls',\n",
       " 'sultry women',\n",
       " 'swastika',\n",
       " 'swinger',\n",
       " 'tainted love',\n",
       " 'taste my',\n",
       " 'tea bagging',\n",
       " 'threesome',\n",
       " 'throating',\n",
       " 'thumbzilla',\n",
       " 'tied up',\n",
       " 'tight white',\n",
       " 'tit',\n",
       " 'tits',\n",
       " 'titties',\n",
       " 'titty',\n",
       " 'tongue in a',\n",
       " 'topless',\n",
       " 'tosser',\n",
       " 'towelhead',\n",
       " 'tranny',\n",
       " 'tribadism',\n",
       " 'tub girl',\n",
       " 'tubgirl',\n",
       " 'tushy',\n",
       " 'twat',\n",
       " 'twink',\n",
       " 'twinkie',\n",
       " 'two girls one cup',\n",
       " 'undressing',\n",
       " 'upskirt',\n",
       " 'urethra play',\n",
       " 'urophilia',\n",
       " 'vagina',\n",
       " 'venus mound',\n",
       " 'viagra',\n",
       " 'vibrator',\n",
       " 'violet wand',\n",
       " 'vorarephilia',\n",
       " 'voyeur',\n",
       " 'voyeurweb',\n",
       " 'voyuer',\n",
       " 'vulva',\n",
       " 'wank',\n",
       " 'wetback',\n",
       " 'wet dream',\n",
       " 'white power',\n",
       " 'whore',\n",
       " 'worldsex',\n",
       " 'wrapping men',\n",
       " 'wrinkled starfish',\n",
       " 'xx',\n",
       " 'xxx',\n",
       " 'yaoi',\n",
       " 'yellow showers',\n",
       " 'yiffy',\n",
       " 'zoophilia']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731ef001",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['suicide',\n",
       " 'suicidal',\n",
       " 'kill',\n",
       " 'death',\n",
       " 'dead',\n",
       " 'murder',\n",
       " 'self-murder',\n",
       " 'self-slaughter',\n",
       " 'self-suicide',\n",
       " 'cut my throat',\n",
       " 'cut my veins',\n",
       " 'slice my veins',\n",
       " 'jump off a bridge',\n",
       " 'in front of a train',\n",
       " 'fall off a bridge',\n",
       " 'hang myself',\n",
       " 'hang up',\n",
       " 'take sleeping pills',\n",
       " 'not want to wake up',\n",
       " 'no longer want to wake up']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigger_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d20bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sentence contains bad words (True or false)\n",
    "\n",
    "def filter_bad_words(sentence, bad_words): \n",
    "    \n",
    "    # load list of bad words\n",
    "    profanity.load_censor_words(bad_words)\n",
    "    \n",
    "    # Check\n",
    "    return profanity.contains_profanity(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75dce0ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Piece of Sh1t\"\n",
    "filter_bad_words(sentence, bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b09a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sentence contains trigger words (True or false)\n",
    "\n",
    "def filter_trigger_words(sentence, trigger_words): \n",
    "    \n",
    "    # load list of bad words\n",
    "    profanity.load_censor_words(trigger_words)\n",
    "    \n",
    "    # Check\n",
    "    return profanity.contains_profanity(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f87978c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "sentence = \"I think about killing myself\"\n",
    "filter_trigger_words(sentence, trigger_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd589b56",
   "metadata": {},
   "source": [
    "## Detect neutral input, emotions and offensive language\n",
    "\n",
    "Model card: https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion\n",
    "\n",
    "Benchmarks: https://arxiv.org/pdf/2010.12421.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750fc2b5",
   "metadata": {},
   "source": [
    "### Neutral input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a167b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate tokenizer and model\n",
    "\n",
    "tokenizer_neut = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model_neut = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d145a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for predicting neutrality / Return true or false\n",
    "\n",
    "def predict_neutrality(text):\n",
    "    \n",
    "    # Labels\n",
    "    labels_neut = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    # Encode\n",
    "    encoded_input = tokenizer_neut(text, return_tensors='pt')\n",
    "    \n",
    "    # Model output\n",
    "    output = model_neut(**encoded_input)\n",
    "    \n",
    "    # Convert output (tensors) to numpy array\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    \n",
    "    # Apply softmax function\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # Convert scores for emotions to dictionary\n",
    "    neutrality = {}\n",
    "    for i in range(len(scores)):\n",
    "        neutrality[labels_neut[i]] = scores[i]\n",
    "        \n",
    "    # Check if user input is neutral or not        \n",
    "    if neutrality['neutral'] > neutrality['negative'] and neutrality['neutral'] > neutrality['positive']:\n",
    "        return True    \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecabc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "text = \"Test\"\n",
    "neutrality = predict_neutrality(text)\n",
    "neutrality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1eb7f",
   "metadata": {},
   "source": [
    "### Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9002a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate tokenizer and model\n",
    "\n",
    "tokenizer_emo = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "model_emo = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fdb0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for predicting emotions / returns dictionary with emotions\n",
    "\n",
    "def predict_emotion(text):\n",
    "    \n",
    "    # Labels\n",
    "    labels_emo = ['anger', 'joy', 'optimism', 'sadness']\n",
    "    \n",
    "    # Encode\n",
    "    encoded_input = tokenizer_emo(text, return_tensors='pt')\n",
    "    \n",
    "    # Model output\n",
    "    output = model_emo(**encoded_input)\n",
    "    \n",
    "    # Convert output (tensors) to numpy array\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    \n",
    "    # Apply softmax function\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # Convert scores for emotions to dictionary\n",
    "    emotions = {}\n",
    "    for i in range(len(scores)):\n",
    "        emotions[labels_emo[i]] = scores[i]\n",
    "    \n",
    "    print(emotions)\n",
    "    \n",
    "    if emotions['anger'] >= 0.9:\n",
    "        return f\"let's calm down a bit\"\n",
    "    else:\n",
    "        if emotions['sadness'] >= 0.9:\n",
    "            return f\"let's talk to a friend\"\n",
    "        else:\n",
    "            return f\"Tell me a joke.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ec686d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0.0047455905, 'joy': 0.0069374996, 'optimism': 0.0040948116, 'sadness': 0.9842221}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"let's talk to a friend\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "text = \"I am a very sad\"\n",
    "predict_emotion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6f4ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0.00440111, 'joy': 0.0067090294, 'optimism': 0.004636546, 'sadness': 0.98425335}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"let's talk to a friend\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "text = \"I am a bit sad\"\n",
    "predict_emotion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53e57954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0.05627922, 'joy': 0.010269949, 'optimism': 0.0049911006, 'sadness': 0.92845976}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"let's talk to a friend\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "text = \"I really want to die\"\n",
    "predict_emotion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4db6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0.9568228, 'joy': 0.014350439, 'optimism': 0.013390444, 'sadness': 0.015436331}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"let's calm down a bit\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "text = \"I want beat someone\"\n",
    "predict_emotion(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "671f401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anger': 0.013719822, 'joy': 0.043690234, 'optimism': 0.90079266, 'sadness': 0.041797217}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tell me a joke.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "text = \"I have a lot of hope\"\n",
    "predict_emotion(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e025cd",
   "metadata": {},
   "source": [
    "### Offensive language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate tokenizer and model\n",
    "\n",
    "tokenizer_off = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-offensive\")\n",
    "model_off = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-offensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for predicting offensive language / Returns True or False\n",
    "### needs to be \n",
    "\n",
    "def predict_offensive(text):\n",
    "    \n",
    "    # Labels\n",
    "    labels_off = ['not-offensive', 'offensive']\n",
    "    \n",
    "    # Encode\n",
    "    encoded_input = tokenizer_off(text, return_tensors='pt')\n",
    "    \n",
    "    # Model output\n",
    "    output = model_off(**encoded_input)\n",
    "    \n",
    "    # Convert output (tensors) to numpy array\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    \n",
    "    # Apply softmax function\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # Convert scores for emotions to dictionary\n",
    "    offensive = {}\n",
    "    for i in range(len(scores)):\n",
    "        offensive[labels_off[i]] = scores[i]\n",
    "        \n",
    "    # Check if text is offensive or not        \n",
    "    if offensive['offensive'] > offensive['not-offensive']:\n",
    "        return True    \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e48031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "text = \"I want to kill you\"\n",
    "offensive = predict_offensive(text)\n",
    "offensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437fc99",
   "metadata": {},
   "source": [
    "# Predict answer in a dialog\n",
    "\n",
    "Paper: https://arxiv.org/pdf/2004.13637.pdf\n",
    "\n",
    "Fine-tuning: https://parl.ai/projects/recipes/\n",
    "\n",
    "Model card: https://huggingface.co/facebook/blenderbot-400M-distill?text=Hey+my+name+is+Mariama%21+How+are+you%3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0332d37",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|████████████████████████████████████████████████████████████| 127k/127k [00:00<00:00, 472kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████| 62.9k/62.9k [00:00<00:00, 290kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████| 1.15k/1.15k [00:00<00:00, 287kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████| 16.0/16.0 [00:00<00:00, 7.15kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████| 772/772 [00:00<00:00, 276kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████| 1.57k/1.57k [00:00<00:00, 978kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████| 730M/730M [05:33<00:00, 2.19MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer_blend = BlenderbotTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "model_blend = BlenderbotForConditionalGeneration.from_pretrained(\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, history=''):\n",
    "\n",
    "    # Check for potential triggers\n",
    "    if filter_trigger_words(text, trigger_words) is True:\n",
    "        ####### Question: Do we need here and in the following hard codes answers the <s> tag that comes with the model output?\n",
    "        output = \"A therapist will be in contact with you shortly.\"\n",
    "        return output, history\n",
    "  \n",
    "    # Check for potential bad words\n",
    "    elif filter_bad_words(text, bad_words) is True:\n",
    "        output = \"Let's try and say this a bit nicer.\"\n",
    "        return output, history\n",
    "    \n",
    "    elif predict_neutrality(text) is True:\n",
    "        output = \"Could you explain further?\"\n",
    "        return output, history\n",
    "    \n",
    "#### Here the emotion analysis needs to step in with the thresholds and hard coded output\n",
    "    \n",
    "  \n",
    "    # If neither triggers nor bad words are present, generate a model output\n",
    "    else:\n",
    "        \n",
    "        # Tokenize input\n",
    "        input_token = tokenizer_blend(text, return_tensors='pt')\n",
    "\n",
    "        # Get result from model\n",
    "        result = model_blend.generate(**input_token)\n",
    "        \n",
    "        # Decode result to model answer\n",
    "        output = tokenizer_blend.decode(result[0])\n",
    "        \n",
    "        # Check model answer for offensive language\n",
    "        if predict_offensive(output) is True:\n",
    "            result = model_blend.generate(**input_token)\n",
    "            output = tokenizer_blend.decode(result[0])\n",
    "\n",
    "            \n",
    "    # Append model answer to history\n",
    "    history = ''.join((history, text, output))\n",
    "\n",
    "    return output, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7372bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> I am sorry to hear that. Why are you sad? Do you want to talk about it?</s>\n",
      "I am sad<s> I am sorry to hear that. Why are you sad? Do you want to talk about it?</s>\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "input1 = 'I am sad'\n",
    "history1 = ''\n",
    "output1, history2 = predict(input1, history1)\n",
    "\n",
    "print(output1)\n",
    "print(history2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88fa0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> I'm sorry to hear that. Do you have any hobbies that you like to do?</s>\n",
      "I am sad<s> I am sorry to hear that. Why are you sad? Do you want to talk about it?</s>No, I do not want to talk<s> I'm sorry to hear that. Do you have any hobbies that you like to do?</s>\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "input2 = 'No, I do not want to talk'\n",
    "\n",
    "output2, history3 = predict(input2, history2)\n",
    "\n",
    "print(output2)\n",
    "print(history3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec123171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> I am sorry to hear that. Why are you sad? Do you want to talk about it?</s>\n",
      "I am sad<s> I am sorry to hear that. Why are you sad? Do you want to talk about it?</s>No, I do not want to talk<s> I'm sorry to hear that. Do you have any hobbies that you like to do?</s>No I am sad<s> I am sorry to hear that. Why are you sad? Do you want to talk about it?</s>\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "input3 = 'No I am sad'\n",
    "\n",
    "output3, history4 = predict(input3, history3)\n",
    "\n",
    "print(output3)\n",
    "print(history4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1875e3b4d47a39b140ad93b3e0c174c085ac6dc8de52e317e3cc5345dcbc697b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
