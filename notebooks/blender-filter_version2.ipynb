{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0b7b6a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ddaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install better_profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f401b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# General \n",
    "\n",
    "# Blendebot\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "# Filter for bad words and trigger words\n",
    "from better_profanity import profanity \n",
    "\n",
    "# Detect neutral input, emotions and offensive language\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285b99b",
   "metadata": {},
   "source": [
    "# Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe16cb",
   "metadata": {},
   "source": [
    "## Trigger words and bad words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5465d52",
   "metadata": {},
   "source": [
    "**To do:**\n",
    "\n",
    "* Review lists of both, bad and trigger words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of bad words and trigger words from folder\n",
    "\n",
    "with open(\"../filter/trigger_words.txt\") as file:\n",
    "    trigger_words = [line.rstrip() for line in file]\n",
    "    \n",
    "with open(\"../filter/bad_words.txt\") as file:\n",
    "    bad_words = [line.rstrip() for line in file] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd7a61",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ef001",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigger_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sentence contains bad words (True or false)\n",
    "\n",
    "def filter_bad_words(sentence, bad_words): \n",
    "    \n",
    "    # load list of bad words\n",
    "    profanity.load_censor_words(bad_words)\n",
    "    \n",
    "    # Check\n",
    "    return profanity.contains_profanity(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dce0ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentence = \"Piece of Sh1t\"\n",
    "filter_bad_words(sentence, bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sentence contains trigger words (True or false)\n",
    "\n",
    "def filter_trigger_words(sentence, trigger_words): \n",
    "    \n",
    "    # load list of bad words\n",
    "    profanity.load_censor_words(trigger_words)\n",
    "    \n",
    "    # Check\n",
    "    return profanity.contains_profanity(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "sentence = \"I think about killing myself\"\n",
    "filter_trigger_words(sentence, trigger_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd589b56",
   "metadata": {},
   "source": [
    "## Detect neutral input, emotions and offensive language\n",
    "\n",
    "Model card: https://huggingface.co/cardiffnlp/twitter-roberta-base-emotion\n",
    "\n",
    "Benchmarks: https://arxiv.org/pdf/2010.12421.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750fc2b5",
   "metadata": {},
   "source": [
    "### Neutral input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a167b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate tokenizer and model\n",
    "\n",
    "tokenizer_neut = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model_neut = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d145a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for predicting neutrality / Return true or false\n",
    "\n",
    "def predict_neutrality(text):\n",
    "    \n",
    "    # Labels\n",
    "    labels_neut = ['negative', 'neutral', 'positive']\n",
    "    \n",
    "    # Encode\n",
    "    encoded_input = tokenizer_neut(text, return_tensors='pt')\n",
    "    \n",
    "    # Model output\n",
    "    output = model_neut(**encoded_input)\n",
    "    \n",
    "    # Convert output (tensors) to numpy array\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    \n",
    "    # Apply softmax function\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # Convert scores for emotions to dictionary\n",
    "    neutrality = {}\n",
    "    for i in range(len(scores)):\n",
    "        neutrality[labels_neut[i]] = scores[i]\n",
    "        \n",
    "    # Check if user input is neutral or not        \n",
    "    if neutrality['neutral'] > neutrality['negative'] and neutrality['neutral'] > neutrality['positive']:\n",
    "        return True    \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecabc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "text = \"Test\"\n",
    "neutrality = predict_neutrality(text)\n",
    "neutrality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1eb7f",
   "metadata": {},
   "source": [
    "### Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate tokenizer and model\n",
    "\n",
    "tokenizer_emo = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "model_emo = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdb0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for predicting emotions / returns dictionary with emotions\n",
    "\n",
    "def predict_emotion(text):\n",
    "    \n",
    "    # Labels\n",
    "    labels_emo = ['anger', 'joy', 'optimism', 'sadness']\n",
    "    \n",
    "    # Encode\n",
    "    encoded_input = tokenizer_emo(text, return_tensors='pt')\n",
    "    \n",
    "    # Model output\n",
    "    output = model_emo(**encoded_input)\n",
    "    \n",
    "    # Convert output (tensors) to numpy array\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    \n",
    "    # Apply softmax function\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # Convert scores for emotions to dictionary\n",
    "    emotions = {}\n",
    "    for i in range(len(scores)):\n",
    "        emotions[labels_emo[i]] = scores[i]\n",
    "    \n",
    "    print(emotions)\n",
    "    \n",
    "    if emotions['anger'] >= 0.9:\n",
    "        return f\"let's calm down a bit\"\n",
    "    else:\n",
    "        return f\"let's party\"\n",
    "    \n",
    "    if emotions['sadness'] >= 0.9:\n",
    "        return f\"let's calm down a bit\"\n",
    "    else:\n",
    "        return f\"let's party\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec686d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "text = \"I want to stone women\"\n",
    "predict_emotion(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e025cd",
   "metadata": {},
   "source": [
    "### Offensive language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate tokenizer and model\n",
    "\n",
    "tokenizer_off = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-offensive\")\n",
    "model_off = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-offensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for predicting offensive language / Returns True or False\n",
    "### needs to be \n",
    "\n",
    "def predict_offensive(text):\n",
    "    \n",
    "    # Labels\n",
    "    labels_off = ['not-offensive', 'offensive']\n",
    "    \n",
    "    # Encode\n",
    "    encoded_input = tokenizer_off(text, return_tensors='pt')\n",
    "    \n",
    "    # Model output\n",
    "    output = model_off(**encoded_input)\n",
    "    \n",
    "    # Convert output (tensors) to numpy array\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    \n",
    "    # Apply softmax function\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    # Convert scores for emotions to dictionary\n",
    "    offensive = {}\n",
    "    for i in range(len(scores)):\n",
    "        offensive[labels_off[i]] = scores[i]\n",
    "        \n",
    "    # Check if text is offensive or not        \n",
    "    if offensive['offensive'] > offensive['not-offensive']:\n",
    "        return True    \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e48031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "text = \"I want to kill you\"\n",
    "offensive = predict_offensive(text)\n",
    "offensive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437fc99",
   "metadata": {},
   "source": [
    "# Predict answer in a dialog\n",
    "\n",
    "Paper: https://arxiv.org/pdf/2004.13637.pdf\n",
    "\n",
    "Fine-tuning: https://parl.ai/projects/recipes/\n",
    "\n",
    "Model card: https://huggingface.co/facebook/blenderbot-400M-distill?text=Hey+my+name+is+Mariama%21+How+are+you%3F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0332d37",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer_blend = BlenderbotTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n",
    "model_blend = BlenderbotForConditionalGeneration.from_pretrained(\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, history=''):\n",
    "\n",
    "    # Check for potential triggers\n",
    "    if filter_trigger_words(text, trigger_words) is True:\n",
    "        ####### Question: Do we need here and in the following hard codes answers the <s> tag that comes with the model output?\n",
    "        output = \"A therapist will be in contact with you shortly.\"\n",
    "        return output, history\n",
    "  \n",
    "    # Check for potential bad words\n",
    "    elif filter_bad_words(text, bad_words) is True:\n",
    "        output = \"Let's try and say this a bit nicer.\"\n",
    "        return output, history\n",
    "    \n",
    "    elif predict_neutrality(text) is True:\n",
    "        output = \"Could you explain further?\"\n",
    "        return output, history\n",
    "    \n",
    "#### Here the emotion analysis needs to step in with the thresholds and hard coded output\n",
    "    \n",
    "  \n",
    "    # If neither triggers nor bad words are present, generate a model output\n",
    "    else:\n",
    "        \n",
    "        # Tokenize input\n",
    "        input_token = tokenizer_blend(text, return_tensors='pt')\n",
    "\n",
    "        # Get result from model\n",
    "        result = model_blend.generate(**input_token)\n",
    "        \n",
    "        # Decode result to model answer\n",
    "        output = tokenizer_blend.decode(result[0])\n",
    "        \n",
    "        # Check model answer for offensive language\n",
    "        if predict_offensive(output) is True:\n",
    "            result = model_blend.generate(**input_token)\n",
    "            output = tokenizer_blend.decode(result[0])\n",
    "\n",
    "            \n",
    "    # Append model answer to history\n",
    "    history = ''.join((history, text, output))\n",
    "\n",
    "    return output, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7372bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "input1 = 'I am sad'\n",
    "history1 = ''\n",
    "output1, history2 = predict(input1, history1)\n",
    "\n",
    "print(output1)\n",
    "print(history2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88fa0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "input2 = 'No, I do not want to talk'\n",
    "\n",
    "output2, history3 = predict(input2, history2)\n",
    "\n",
    "print(output2)\n",
    "print(history3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec123171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model\n",
    "input3 = 'No I am sad'\n",
    "\n",
    "output3, history4 = predict(input3, history3)\n",
    "\n",
    "print(output3)\n",
    "print(history4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 18 2022, 11:40:18) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1875e3b4d47a39b140ad93b3e0c174c085ac6dc8de52e317e3cc5345dcbc697b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
