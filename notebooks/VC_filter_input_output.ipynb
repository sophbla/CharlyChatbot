{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cb963de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09ed394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 2.36k/2.36k [00:00<00:00, 955kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 2.42M/2.42M [00:01<00:00, 1.83MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 37.0/37.0 [00:00<00:00, 13.1kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████| 2.20k/2.20k [00:00<00:00, 1.05MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 1.49k/1.49k [00:00<00:00, 209kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 892M/892M [05:14<00:00, 2.84MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/GODEL-v1_1-base-seq2seq\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"microsoft/GODEL-v1_1-base-seq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3d70b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_input, history):\n",
    "\n",
    "    # Basic instruction\n",
    "    instruction = 'Instruction: given a dialog context, you need to response empathically.'\n",
    "\n",
    "    # Knowledge given\n",
    "    knowledge = '  '\n",
    "\n",
    "    # Copy history of dialog\n",
    "    dialog_list = history.copy()\n",
    "\n",
    "    # Append user input to dialog\n",
    "    dialog_list.append(user_input)\n",
    "\n",
    "    # Prepare dialog to be used in the model\n",
    "    dialog = ' EOS '.join(dialog_list)\n",
    "\n",
    "    # Build query \n",
    "    ### Question: What does [CONTEXT] do???\n",
    "    query = f\"{instruction} [CONTEXT] {dialog} {knowledge}\"\n",
    "\n",
    "    # Tokenize the new input sentence\n",
    "    new_user_input_ids = tokenizer.encode(f\"{query}\", return_tensors='pt')\n",
    "\n",
    "    # Set params for model output\n",
    "    top_p = 0.9 # What is this???\n",
    "    min_length = 8\n",
    "    max_length = 200\n",
    "\n",
    "    # Generate output\n",
    "    output = model.generate(new_user_input_ids, \n",
    "                            min_length=int(min_length), \n",
    "                            max_length=int(max_length), \n",
    "                            top_p=top_p, \n",
    "                            do_sample=True)          \n",
    "\n",
    "    # Decode output\n",
    "    ### Removed \".tolist()\"\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)   \n",
    "\n",
    "    # Create new history of dialog\n",
    "    dialog_list.append(response)\n",
    "\n",
    "    return response, dialog_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ae7a6c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Yes. Let's just say that you like the color scheme, or it's different than a lot of colors.\",\n",
       " ['Can you help my?',\n",
       "  \"Yes. Let's just say that you like the color scheme, or it's different than a lot of colors.\"])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = 'Can you help my?'\n",
    "history1 = []\n",
    "predict(input1, first_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b8f9bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of bad words\n",
    "with open(\"filter/bad_words.txt\") as file:\n",
    "    bad_words = [line.rstrip() for line in file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e56e9873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2g1c',\n",
       " '2 girls 1 cup',\n",
       " 'acrotomophilia',\n",
       " 'alabama hot pocket',\n",
       " 'alaskan pipeline',\n",
       " 'anal',\n",
       " 'anilingus',\n",
       " 'anus',\n",
       " 'apeshit',\n",
       " 'arsehole',\n",
       " 'ass',\n",
       " 'asshole',\n",
       " 'assmunch',\n",
       " 'auto erotic',\n",
       " 'autoerotic',\n",
       " 'babeland',\n",
       " 'baby batter',\n",
       " 'baby juice',\n",
       " 'ball gag',\n",
       " 'ball gravy',\n",
       " 'ball kicking',\n",
       " 'ball licking',\n",
       " 'ball sack',\n",
       " 'ball sucking',\n",
       " 'bangbros',\n",
       " 'bangbus',\n",
       " 'bareback',\n",
       " 'barely legal',\n",
       " 'barenaked',\n",
       " 'bastard',\n",
       " 'bastardo',\n",
       " 'bastinado',\n",
       " 'bbw',\n",
       " 'bdsm',\n",
       " 'beaner',\n",
       " 'beaners',\n",
       " 'beaver cleaver',\n",
       " 'beaver lips',\n",
       " 'beastiality',\n",
       " 'bestiality',\n",
       " 'big black',\n",
       " 'big breasts',\n",
       " 'big knockers',\n",
       " 'big tits',\n",
       " 'bimbos',\n",
       " 'birdlock',\n",
       " 'bitch',\n",
       " 'bitches',\n",
       " 'black cock',\n",
       " 'blonde action',\n",
       " 'blonde on blonde action',\n",
       " 'blowjob',\n",
       " 'blow job',\n",
       " 'blow your load',\n",
       " 'blue waffle',\n",
       " 'blumpkin',\n",
       " 'bollocks',\n",
       " 'bondage',\n",
       " 'boner',\n",
       " 'boob',\n",
       " 'boobs',\n",
       " 'booty call',\n",
       " 'brown showers',\n",
       " 'brunette action',\n",
       " 'bukkake',\n",
       " 'bulldyke',\n",
       " 'bullet vibe',\n",
       " 'bullshit',\n",
       " 'bung hole',\n",
       " 'bunghole',\n",
       " 'busty',\n",
       " 'butt',\n",
       " 'buttcheeks',\n",
       " 'butthole',\n",
       " 'camel toe',\n",
       " 'camgirl',\n",
       " 'camslut',\n",
       " 'camwhore',\n",
       " 'carpet muncher',\n",
       " 'carpetmuncher',\n",
       " 'chocolate rosebuds',\n",
       " 'cialis',\n",
       " 'circlejerk',\n",
       " 'cleveland steamer',\n",
       " 'clit',\n",
       " 'clitoris',\n",
       " 'clover clamps',\n",
       " 'clusterfuck',\n",
       " 'cock',\n",
       " 'cocks',\n",
       " 'coprolagnia',\n",
       " 'coprophilia',\n",
       " 'cornhole',\n",
       " 'coon',\n",
       " 'coons',\n",
       " 'creampie',\n",
       " 'cum',\n",
       " 'cumming',\n",
       " 'cumshot',\n",
       " 'cumshots',\n",
       " 'cunnilingus',\n",
       " 'cunt',\n",
       " 'darkie',\n",
       " 'date rape',\n",
       " 'daterape',\n",
       " 'deep throat',\n",
       " 'deepthroat',\n",
       " 'dendrophilia',\n",
       " 'dick',\n",
       " 'dildo',\n",
       " 'dingleberry',\n",
       " 'dingleberries',\n",
       " 'dirty pillows',\n",
       " 'dirty sanchez',\n",
       " 'doggie style',\n",
       " 'doggiestyle',\n",
       " 'doggy style',\n",
       " 'doggystyle',\n",
       " 'dog style',\n",
       " 'dolcett',\n",
       " 'domination',\n",
       " 'dominatrix',\n",
       " 'dommes',\n",
       " 'donkey punch',\n",
       " 'double dong',\n",
       " 'double penetration',\n",
       " 'dp action',\n",
       " 'dry hump',\n",
       " 'dvda',\n",
       " 'eat my ass',\n",
       " 'ecchi',\n",
       " 'ejaculation',\n",
       " 'erotic',\n",
       " 'erotism',\n",
       " 'escort',\n",
       " 'eunuch',\n",
       " 'fag',\n",
       " 'faggot',\n",
       " 'fecal',\n",
       " 'felch',\n",
       " 'fellatio',\n",
       " 'feltch',\n",
       " 'female squirting',\n",
       " 'femdom',\n",
       " 'figging',\n",
       " 'fingerbang',\n",
       " 'fingering',\n",
       " 'fisting',\n",
       " 'foot fetish',\n",
       " 'footjob',\n",
       " 'frotting',\n",
       " 'fuck',\n",
       " 'fuck buttons',\n",
       " 'fuckin',\n",
       " 'fucking',\n",
       " 'fucktards',\n",
       " 'fudge packer',\n",
       " 'fudgepacker',\n",
       " 'futanari',\n",
       " 'gangbang',\n",
       " 'gang bang',\n",
       " 'gay sex',\n",
       " 'genitals',\n",
       " 'giant cock',\n",
       " 'girl on',\n",
       " 'girl on top',\n",
       " 'girls gone wild',\n",
       " 'goatcx',\n",
       " 'goatse',\n",
       " 'god damn',\n",
       " 'gokkun',\n",
       " 'golden shower',\n",
       " 'goodpoop',\n",
       " 'goo girl',\n",
       " 'goregasm',\n",
       " 'grope',\n",
       " 'group sex',\n",
       " 'g-spot',\n",
       " 'guro',\n",
       " 'hand job',\n",
       " 'handjob',\n",
       " 'hard core',\n",
       " 'hardcore',\n",
       " 'hentai',\n",
       " 'homoerotic',\n",
       " 'honkey',\n",
       " 'hooker',\n",
       " 'horny',\n",
       " 'hot carl',\n",
       " 'hot chick',\n",
       " 'how to kill',\n",
       " 'how to murder',\n",
       " 'huge fat',\n",
       " 'humping',\n",
       " 'incest',\n",
       " 'intercourse',\n",
       " 'jack off',\n",
       " 'jail bait',\n",
       " 'jailbait',\n",
       " 'jelly donut',\n",
       " 'jerk off',\n",
       " 'jigaboo',\n",
       " 'jiggaboo',\n",
       " 'jiggerboo',\n",
       " 'jizz',\n",
       " 'juggs',\n",
       " 'kike',\n",
       " 'kinbaku',\n",
       " 'kinkster',\n",
       " 'kinky',\n",
       " 'knobbing',\n",
       " 'leather restraint',\n",
       " 'leather straight jacket',\n",
       " 'lemon party',\n",
       " 'livesex',\n",
       " 'lolita',\n",
       " 'lovemaking',\n",
       " 'make me come',\n",
       " 'male squirting',\n",
       " 'masturbate',\n",
       " 'masturbating',\n",
       " 'masturbation',\n",
       " 'menage a trois',\n",
       " 'milf',\n",
       " 'missionary position',\n",
       " 'mong',\n",
       " 'motherfucker',\n",
       " 'mound of venus',\n",
       " 'mr hands',\n",
       " 'muff diver',\n",
       " 'muffdiving',\n",
       " 'nambla',\n",
       " 'nawashi',\n",
       " 'negro',\n",
       " 'neonazi',\n",
       " 'nigga',\n",
       " 'nigger',\n",
       " 'nig nog',\n",
       " 'nimphomania',\n",
       " 'nipple',\n",
       " 'nipples',\n",
       " 'nsfw',\n",
       " 'nsfw images',\n",
       " 'nude',\n",
       " 'nudity',\n",
       " 'nutten',\n",
       " 'nympho',\n",
       " 'nymphomania',\n",
       " 'octopussy',\n",
       " 'omorashi',\n",
       " 'one cup two girls',\n",
       " 'one guy one jar',\n",
       " 'orgasm',\n",
       " 'orgy',\n",
       " 'paedophile',\n",
       " 'paki',\n",
       " 'panties',\n",
       " 'panty',\n",
       " 'pedobear',\n",
       " 'pedophile',\n",
       " 'pegging',\n",
       " 'penis',\n",
       " 'phone sex',\n",
       " 'piece of shit',\n",
       " 'pikey',\n",
       " 'pissing',\n",
       " 'piss pig',\n",
       " 'pisspig',\n",
       " 'playboy',\n",
       " 'pleasure chest',\n",
       " 'pole smoker',\n",
       " 'ponyplay',\n",
       " 'poof',\n",
       " 'poon',\n",
       " 'poontang',\n",
       " 'punany',\n",
       " 'poop chute',\n",
       " 'poopchute',\n",
       " 'porn',\n",
       " 'porno',\n",
       " 'pornography',\n",
       " 'prince albert piercing',\n",
       " 'pthc',\n",
       " 'pubes',\n",
       " 'pussy',\n",
       " 'queaf',\n",
       " 'queef',\n",
       " 'quim',\n",
       " 'raghead',\n",
       " 'raging boner',\n",
       " 'rape',\n",
       " 'raping',\n",
       " 'rapist',\n",
       " 'rectum',\n",
       " 'reverse cowgirl',\n",
       " 'rimjob',\n",
       " 'rimming',\n",
       " 'rosy palm',\n",
       " 'rosy palm and her 5 sisters',\n",
       " 'rusty trombone',\n",
       " 'sadism',\n",
       " 'santorum',\n",
       " 'scat',\n",
       " 'schlong',\n",
       " 'scissoring',\n",
       " 'semen',\n",
       " 'sex',\n",
       " 'sexcam',\n",
       " 'sexo',\n",
       " 'sexy',\n",
       " 'sexual',\n",
       " 'sexually',\n",
       " 'sexuality',\n",
       " 'shaved beaver',\n",
       " 'shaved pussy',\n",
       " 'shemale',\n",
       " 'shibari',\n",
       " 'shit',\n",
       " 'shitblimp',\n",
       " 'shitty',\n",
       " 'shota',\n",
       " 'shrimping',\n",
       " 'skeet',\n",
       " 'slanteye',\n",
       " 'slut',\n",
       " 's&m',\n",
       " 'smut',\n",
       " 'snatch',\n",
       " 'snowballing',\n",
       " 'sodomize',\n",
       " 'sodomy',\n",
       " 'spastic',\n",
       " 'spic',\n",
       " 'splooge',\n",
       " 'splooge moose',\n",
       " 'spooge',\n",
       " 'spread legs',\n",
       " 'spunk',\n",
       " 'strap on',\n",
       " 'strapon',\n",
       " 'strappado',\n",
       " 'strip club',\n",
       " 'style doggy',\n",
       " 'suck',\n",
       " 'sucks',\n",
       " 'suicide girls',\n",
       " 'sultry women',\n",
       " 'swastika',\n",
       " 'swinger',\n",
       " 'tainted love',\n",
       " 'taste my',\n",
       " 'tea bagging',\n",
       " 'threesome',\n",
       " 'throating',\n",
       " 'thumbzilla',\n",
       " 'tied up',\n",
       " 'tight white',\n",
       " 'tit',\n",
       " 'tits',\n",
       " 'titties',\n",
       " 'titty',\n",
       " 'tongue in a',\n",
       " 'topless',\n",
       " 'tosser',\n",
       " 'towelhead',\n",
       " 'tranny',\n",
       " 'tribadism',\n",
       " 'tub girl',\n",
       " 'tubgirl',\n",
       " 'tushy',\n",
       " 'twat',\n",
       " 'twink',\n",
       " 'twinkie',\n",
       " 'two girls one cup',\n",
       " 'undressing',\n",
       " 'upskirt',\n",
       " 'urethra play',\n",
       " 'urophilia',\n",
       " 'vagina',\n",
       " 'venus mound',\n",
       " 'viagra',\n",
       " 'vibrator',\n",
       " 'violet wand',\n",
       " 'vorarephilia',\n",
       " 'voyeur',\n",
       " 'voyeurweb',\n",
       " 'voyuer',\n",
       " 'vulva',\n",
       " 'wank',\n",
       " 'wetback',\n",
       " 'wet dream',\n",
       " 'white power',\n",
       " 'whore',\n",
       " 'worldsex',\n",
       " 'wrapping men',\n",
       " 'wrinkled starfish',\n",
       " 'xx',\n",
       " 'xxx',\n",
       " 'yaoi',\n",
       " 'yellow showers',\n",
       " 'yiffy',\n",
       " 'zoophilia']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4757ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of trigger words\n",
    "with open(\"filter/trigger_words.txt\") as file:\n",
    "    trigger_words = [line.rstrip() for line in file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "42f7c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['suicide',\n",
       " 'suicidal',\n",
       " 'kill',\n",
       " 'death',\n",
       " 'dead',\n",
       " 'murder',\n",
       " 'self-murder',\n",
       " 'self-slaughter',\n",
       " 'self-suicide',\n",
       " 'cut my throat',\n",
       " 'cut my veins',\n",
       " 'slice my veins',\n",
       " 'jump off a bridge',\n",
       " 'in front of a train',\n",
       " 'fall off a bridge',\n",
       " 'hang myself',\n",
       " 'hang up',\n",
       " 'take sleeping pills',\n",
       " 'not want to wake up',\n",
       " 'no longer want to wake up']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigger_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "418b3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic preprocessing for filtering \n",
    "def filter_preprocessing(sentence):    \n",
    "    # lower all words\n",
    "    sentence = sentence.lower()    \n",
    "    # remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '')        \n",
    "    # strip withespaces\n",
    "    sentence = sentence.strip()    \n",
    "    return sentence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f0c4fd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello i like you'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_preprocessing('Hello, I like you!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "13034b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for bad words\n",
    "def check_bad_words(sentence, bad_words): \n",
    "    for word in sentence.split():        \n",
    "        if word in bad_words:\n",
    "            return True                \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "ce3c31b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evil_sentence = 'I fuck you'\n",
    "check_bad_words(evil_sentence, bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8aa09830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_sentence = 'I love you'\n",
    "check_bad_words(good_sentence, bad_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8736b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for trigger words\n",
    "def check_trigger_words(sentence, trigger_words):\n",
    "    for word in sentence.split():        \n",
    "        if word in trigger_words:\n",
    "            return True                \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "ab885ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigger_sentence = 'I will kill myself'\n",
    "check_trigger_words(trigger_sentence, trigger_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "22d1879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_trigger_sentence = 'I will love myself'\n",
    "check_trigger_words(no_trigger_sentence, trigger_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "3e62c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nice output\n",
    "def get_nice_response(response, user_input, history, history_updated):\n",
    "    \n",
    "    if check_bad_words(response, bad_words):\n",
    "        new_response, new_history_updated = predict(input, history)\n",
    "        return new_response, new_history_updated\n",
    "    else:\n",
    "        return response, history_updated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1aa6c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Nice to see you too! ', ['Nice to see you', 'Nice to see you too! '])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = 'Nice to see you'\n",
    "response = 'I fuck you'\n",
    "history = []\n",
    "history_updated = ['Nice to see you', response]\n",
    "\n",
    "get_nice_response(response, input2, history, history_updated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "706a8672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_filter(user_input, history, bad_words, trigger_words):\n",
    "    \n",
    "    #### Filter input \n",
    "    \n",
    "    # Basic preprocessing for input filter\n",
    "    input_sentence = filter_preprocessing(user_input)\n",
    "\n",
    "    \n",
    "    # Check for bad words and respond without predicting   \n",
    "    if check_bad_words(input_sentence, bad_words):\n",
    "        response = 'Rethink your language'\n",
    "        return response, history\n",
    "    \n",
    "    # Check for trigger words and respond without predicting\n",
    "    if check_trigger_words(input_sentence, trigger_words):\n",
    "        response = 'You used a trigger word'\n",
    "        return response, history\n",
    "    \n",
    "    ### Get prediction from model ####\n",
    "\n",
    "    model_response, history_updated = predict(user_input, history)\n",
    "    \n",
    "    ### Filter output\n",
    "        \n",
    "    # Basic preprocessing for output filter\n",
    "    response_sentence = filter_preprocessing(model_response)\n",
    "    \n",
    "    # Get new response if response contains bad words    \n",
    "    model_response, history_updated = get_nice_response(model_response, user_input, history, history_updated)\n",
    "    \n",
    "    return model_response, history_updated\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "46b1e3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('We are going to the new YMCA.',\n",
       " ['I love you very much', 'We are going to the new YMCA.'])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = 'I love you very much'\n",
    "history2 = []\n",
    "predict_with_filter(input2, history2, bad_words, trigger_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f0eee6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Rethink your language', [])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = 'I fuck you'\n",
    "history2 = []\n",
    "predict_with_filter(input2, history2, bad_words, trigger_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "52522aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('You used a trigger word', [])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = 'I kill you'\n",
    "history2 = []\n",
    "predict_with_filter(input2, history2, bad_words, trigger_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
